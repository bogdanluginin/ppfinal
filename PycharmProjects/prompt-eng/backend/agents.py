# agents.py
import os
import google.generativeai as genai
from dotenv import load_dotenv
from prompts import SYSTEM_PROMPTS

# –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –∫–ª—é—á–∞
load_dotenv()
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))


class AgentSystem:
    def __init__(self):
        # –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –Ω–æ–≤—É –º–æ–¥–µ–ª—å, –¥–æ—Å—Ç—É–ø–Ω—É –≤–∞–º
        self.model = genai.GenerativeModel('gemini-2.5-flash')

    def _call_llm(self, role_prompt, user_input, context="", history=""):
        """–î–æ–ø–æ–º—ñ–∂–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –∑–∞–ø–∏—Ç—É –¥–æ LLM"""
        combined_prompt = f"""
        SYSTEM INSTRUCTIONS (ROLE):
        {role_prompt}

        PATIENT HISTORY (Previous Chat):
        {history}

        INTERNAL CONTEXT (Previous Doctors in this turn):
        {context}

        CURRENT PATIENT INPUT:
        {user_input}
        """
        try:
            response = self.model.generate_content(combined_prompt)
            return response.text
        except Exception as e:
            return f"Error generating content: {e}"

    def run_medical_council(self, patient_symptoms, response_format="text", history=""):
        logs = []

        # --- –ö–†–û–ö 1: –°—ñ–º–µ–π–Ω–∏–π –ª—ñ–∫–∞—Ä (Triage) ---
        doc_response = self._call_llm(SYSTEM_PROMPTS['family_doctor'], patient_symptoms, history=history)
        logs.append(f"üë®‚Äç‚öïÔ∏è Family Doctor: {doc_response}")

        # --- –ö–†–û–ö 2: –ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü—ñ—è ---
        specialist_response = ""

        if "REFER: PHTHISIATRICIAN" in doc_response:
            # –ù–∞–ø—Ä–∞–≤–ª—è—î–º–æ –¥–æ –§—Ç–∏–∑—ñ–∞—Ç—Ä–∞
            spec_prompt = SYSTEM_PROMPTS['phthisiatrician']
            specialist_response = self._call_llm(spec_prompt, patient_symptoms, context=doc_response, history=history)
            logs.append(f"ü©ª Phthisiatrician: {specialist_response}")
        else:
            # –ù–∞–ø—Ä–∞–≤–ª—è—î–º–æ –¥–æ –Ü–Ω—Ñ–µ–∫—Ü—ñ–æ–Ω—ñ—Å—Ç–∞
            spec_prompt = SYSTEM_PROMPTS['infectious_specialist']
            specialist_response = self._call_llm(spec_prompt, patient_symptoms, context=doc_response, history=history)
            logs.append(f"ü¶† Infectious Specialist: {specialist_response}")

        # --- –ö–†–û–ö 3: –ö–æ–æ—Ä–¥–∏–Ω–∞—Ç–æ—Ä (–§—ñ–Ω–∞–ª—å–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å) ---
        coord_context = f"Family Doc: {doc_response}\nSpecialist Report: {specialist_response}"
        
        # –í–∏–±—ñ—Ä –ø—Ä–æ–º–ø—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ñ–æ—Ä–º–∞—Ç—É
        if response_format == "table":
            coord_prompt = SYSTEM_PROMPTS['coordinator'] # –¶–µ —Ç–∞–±–ª–∏—á–Ω–∏–π –ø—Ä–æ–º–ø—Ç
        else:
            coord_prompt = SYSTEM_PROMPTS.get('coordinator_text', SYSTEM_PROMPTS['coordinator']) # –¢–µ–∫—Å—Ç–æ–≤–∏–π –∞–±–æ –¥–µ—Ñ–æ–ª—Ç–Ω–∏–π

        final_report = self._call_llm(coord_prompt, patient_symptoms, context=coord_context, history=history)

        return {
            "final_report": final_report,
            "logs": logs
        }

    def generate_title(self, user_message):
        """Generates a short, concise title for the chat based on the first message."""
        prompt = f"""
        Analyze the following patient data/symptoms and generate a VERY SHORT title (max 4-5 words).
        If a patient name is present, use it. Format: "Name - Condition" or just "Condition" if no name.
        Do not use markdown or special characters. Keep it clinical and concise.
        
        Input: {user_message}
        Title:
        """
        try:
            response = self.model.generate_content(prompt)
            return response.text.strip()
        except:
            return "Clinical Case"